{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Extracting data from the UKGWA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNl9e1URo0Nk2CXIcsjgl+Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d08019e8f1ee4f179575d9e41a4b002c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_options_labels": [
              "Environment Agency",
              "Salt",
              "Butterflies",
              "Space Education",
              "Professional Standards",
              "Investors in People"
            ],
            "_view_name": "DropdownView",
            "style": "IPY_MODEL_d36a392298324549a8daacc853aa1c94",
            "_dom_classes": [],
            "description": "",
            "_model_name": "DropdownModel",
            "index": 0,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_791b1da7ac7c47129eba54b425f1f5fd"
          }
        },
        "d36a392298324549a8daacc853aa1c94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "791b1da7ac7c47129eba54b425f1f5fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nationalarchives/UKGWA-computational-access/blob/main/Extracting_data_from_the_UKGWA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXOdnNLzO1fK"
      },
      "source": [
        "## Load library functions and data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTza1RbNLG25"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.pyplot import figure\n",
        "from operator import itemgetter\n",
        "import datetime\n",
        "from gensim.summarization import summarizer\n",
        "# Function to convert snapshot timestamp to a date\n",
        "snap_to_date = lambda d : datetime.datetime.strptime(str(d), '%Y%m%d%H%M%S') # %I:%M%p')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3URYl6-UL-95",
        "outputId": "370bb4fc-5a76-4de0-da9e-2beda8182eb6"
      },
      "source": [
        "if os.path.isdir('UKGWA-computational-access'):\n",
        "    shutil.rmtree('UKGWA-computational-access')\n",
        "!git clone https://github.com/nationalarchives/UKGWA-computational-access.git\n",
        "sys.path.insert(0, 'UKGWA-computational-access/Code')\n",
        "data_folder = \"./UKGWA-computational-access/Data/\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'UKGWA-computational-access'...\n",
            "remote: Enumerating objects: 181, done.\u001b[K\n",
            "remote: Counting objects: 100% (181/181), done.\u001b[K\n",
            "remote: Compressing objects: 100% (136/136), done.\u001b[K\n",
            "remote: Total 181 (delta 91), reused 110 (delta 42), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (181/181), 15.00 MiB | 20.45 MiB/s, done.\n",
            "Resolving deltas: 100% (91/91), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmz7oeoQMBvZ"
      },
      "source": [
        "from ukgwa_textindex import UKGWATextIndex\n",
        "from ukgwa_cdx_indexer import TemporalIndexer\n",
        "from ukgwa_index import UKGWAIndex\n",
        "from ukgwa_url import UKGWAurl\n",
        "from disco_search import DiscoSearch\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import ipywidgets"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuYSYaGI2bS2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "715e7335-4edb-4b5b-e1df-3b777a5636ef"
      },
      "source": [
        "!pip install boilerpy3\n",
        "import boilerpy3\n",
        "from boilerpy3 import extractors"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting boilerpy3\n",
            "  Downloading boilerpy3-1.0.5-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: boilerpy3\n",
            "Successfully installed boilerpy3-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsYTMrrCleqm"
      },
      "source": [
        "ukgwa_prefix = \"https://webarchive.nationalarchives.gov.uk/ukgwa/\"\n",
        "examples = [[\"Environment Agency\", \"http://www.environment-agency.gov.uk:80\",\"19961104034437\"],\n",
        "            [\"Salt\", \"http://www.salt.gov.uk\", \"20090810121540\"],\n",
        "            [\"Butterflies\", \"http://www.ukbms.org\", \"20140402194840\"],\n",
        "            [\"Space Education\", \"http://www.esero.org.uk\", \"20140508193217\"],\n",
        "            [\"Professional Standards\", \"http://www.professionalstandards.org.uk\", \"20160506161604\"],\n",
        "            [\"Investors in People\", \"http://www.investorsinpeople.co.uk/Pages/Home.aspx\", \"20120418183519\"]]\n",
        "example_dropdown = ipywidgets.widgets.Dropdown(options=[e[0] for e in examples])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JHoVWTjiGky"
      },
      "source": [
        "## Extracting links from archived web pages\n",
        "\n",
        "Opening and extracting from a web page is made easy by the Python library BeautifulSoup. It converts an HTML page into structural elements and provides functions for navigating the structure and extracting elements by type.\n",
        "One element which is of interest is the hyperlink. This consists of a descriptive label and address of a web page. By extracting all of the links from a page, or a set of pages, we can create the data to perform network analysis.\n",
        "Before doing that we need to be aware of the varying formats of urls which appear on a page.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjVMwrXr7KSC"
      },
      "source": [
        "The Environment Agency page has two formats of link: snapshot + page, or ./page. The latter is known as relative addressing which means it refers to files which are in a sub-folder of the current page address. The former we will call snapshot format.\n",
        "\n",
        "The Salt home page also includes two formats: this time the relative addresses do not include the ./. There are also two links to a page in a different domain (food.gov.uk). In this case the address not only includes the snapshot but also has the prefix of the web archive domain. We will refer to this a complete address. An address in this format can be immediately navigated to (or crawled) without any pre-processing of the address.\n",
        "\n",
        "The remainder of the sites follow similar patterns.\n",
        "\n",
        "Begin by running the first code block to refresh the dropdown menu of example web pages. Once that is done you can select a page from the list and run the following block to see links from the selected site, as many times as you wish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d08019e8f1ee4f179575d9e41a4b002c",
            "d36a392298324549a8daacc853aa1c94",
            "791b1da7ac7c47129eba54b425f1f5fd"
          ]
        },
        "id": "QGW691XJjiXS",
        "outputId": "31839cfa-f918-4af7-fd63-bee7152872d2"
      },
      "source": [
        "example_dropdown"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d08019e8f1ee4f179575d9e41a4b002c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Dropdown(options=('Environment Agency', 'Salt', 'Butterflies', 'Space Education', 'Professional Standards', 'I…"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDxxk8DhOcT1",
        "outputId": "cc346436-333e-4050-b96c-b704838ad677"
      },
      "source": [
        "ex_id = example_dropdown.index\n",
        "\n",
        "ex = examples[ex_id]\n",
        "ex_url = UKGWAurl(ex[2] + \"/\" + ex[1])\n",
        "page = requests.get(ex_url.get_url(crawl=True))\n",
        "soup = BeautifulSoup(page.content, 'html.parser')\n",
        "\n",
        "print(\"Links from\", ex_url.get_url(prefix=False))\n",
        "links = soup.find_all('a')\n",
        "for ln in links:\n",
        "    if ln.has_attr('href'):\n",
        "        print(\"\\t\",ln['href'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://webarchive.nationalarchives.gov.uk/ukgwa/19961104034437mp_/http://www.environment-agency.gov.uk:80\n",
            "Links from 19961104034437/http://www.environment-agency.gov.uk:80\n",
            "\t /ukgwa/19961104034437mp_/http://www.environment-agency.gov.uk:80/cgi-bin/imagemap/maps/ea-home.map\n",
            "\t ./who.html\n",
            "\t /ukgwa/19961104034437mp_/http://www.environment-agency.gov.uk:80/text/home.html\n",
            "\t ./s-enviro.html\n",
            "\t /ukgwa/19961104034437mp_/http://www.environment-agency.gov.uk:80/new.html\n",
            "\t ./info.html\n",
            "\t ./who/hotline.html\n",
            "\t ./publications.html\n",
            "\t ./education.html\n",
            "\t ./feedback.html\n",
            "\t ./search.html\n",
            "\t /ukgwa/19961104034437mp_/http://www.environment-agency.gov.uk:80/cgi-bin/imagemap/maps/ea-nav.map\n",
            "\t mailto:webmaster@environment-agency.gov.uk\n",
            "\t /ukgwa/19961104034437mp_/http://www.environment-agency.gov.uk:80/new.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRTItrkenZNU"
      },
      "source": [
        "What the preceding code has demonstrated is that a certain amount of pre-processing is necessary to resolve link addresses to valid web archive addresses (complete addresses). The solution is simple but is a step that users should be aware of. The following steps should be taken to standardise addresses:\n",
        "\n",
        "1. Complete addresses: leave as they are\n",
        "2. Snapshot addresses: prefix with \"https://webarchive.nationalarchives.gov.uk/ukgwa/\"\n",
        "3. Relative addresses: prefix with the complete address of the page containing the link which must also end in a \"/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW5QbU9Bo_Eu"
      },
      "source": [
        "The next thing to be aware of is that the snapshot timestamp in a web archive URL does not necessarily point to an existing page. The timestamp of a page refers to the time it was crawled which may have occurred seconds or even years after the timestamp in a hyperlink to that page.\n",
        "\n",
        "We can use the CDX data to further analyse this. From the Environment Agency homepage we see that their State of the Environment report was captured 1154 seconds (19 minutes) later than the link address."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-L82bWL6vzuW",
        "outputId": "45fa043c-9cc1-43aa-d844-9eae68a0eaa0"
      },
      "source": [
        "T = TemporalIndexer()\n",
        "url = \"http://www.environment-agency.gov.uk:80/s-enviro.html\"\n",
        "snapshot = 19961104034437\n",
        "T.add_entry(url)\n",
        "nearest_snapshot = snap_to_date(T.get_field(url, 'CDX').nearest_to(19961104034437))\n",
        "(nearest_snapshot - snap_to_date(snapshot))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datetime.timedelta(seconds=1154)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIHe5MbczGxq"
      },
      "source": [
        "In constrast, the \"Who we are\" page was first captured over 467 days later than the link address states. This is an extreme example but makes the point that whether a page linked to is crawled or not depends on both the depth of the crawl and the success of crawling an individual page."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOyMe8uByDF3",
        "outputId": "87b7c304-ce64-4983-82b5-5191ccd97c4e"
      },
      "source": [
        "T = TemporalIndexer()\n",
        "url = \"http://www.environment-agency.gov.uk:80/who.html\"\n",
        "snapshot = 19961104034437\n",
        "T.add_entry(url)\n",
        "nearest_snapshot = snap_to_date(T.get_field(url, 'CDX').nearest_to(19961104034437))\n",
        "(nearest_snapshot - snap_to_date(snapshot))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datetime.timedelta(days=467, seconds=26444)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fpyvkc_18Ayw"
      },
      "source": [
        "## Extracting content from archived web pages\n",
        "\n",
        "One challenge with working with HTML pages is extracting text from those pages. Using the same examples from before, we can use the BeautifulSoup library to extract text from each page.\n",
        "\n",
        "It should be immediately obvious that this is messy as the text also includes a javascript program which is used to render the page in the web archive interface.\n",
        "\n",
        "As before, run the code to refresh the dropdown list before running the text extraction code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWTEyHjn9iN-",
        "outputId": "8d0e170f-7280-4a87-af18-af6346db22ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d08019e8f1ee4f179575d9e41a4b002c",
            "d36a392298324549a8daacc853aa1c94",
            "791b1da7ac7c47129eba54b425f1f5fd"
          ]
        }
      },
      "source": [
        "example_dropdown"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d08019e8f1ee4f179575d9e41a4b002c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Dropdown(options=('Environment Agency', 'Salt', 'Butterflies', 'Space Education', 'Professional Standards', 'I…"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjGignTc2ZV5",
        "outputId": "7d76afa9-61d7-4611-8406-f191c49a3797",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "ex_id = example_dropdown.index\n",
        "ex = examples[ex_id]\n",
        "ex_url = UKGWAurl(ex[2] + \"/\" + ex[1])\n",
        "page = requests.get(ex_url.get_url(crawl=True))\n",
        "soup = BeautifulSoup(page.content, 'html.parser')\n",
        "soup.get_text()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n\\n\\n\\n  wbinfo = {};\\n  wbinfo.top_url = \"https://webarchive.nationalarchives.gov.uk/ukgwa/19961104034437/http://www.environment-agency.gov.uk:80/\";\\n  // Fast Top-Frame Redirect\\n  if (window == window.top && wbinfo.top_url) {\\n    var loc = window.location.href.replace(window.location.hash, \"\");\\n    loc = decodeURI(loc);\\n \\n    if (loc != decodeURI(wbinfo.top_url)) {\\n        window.location.href = wbinfo.top_url + window.location.hash;\\n    }\\n  }\\n  wbinfo.url = \"http://www.environment-agency.gov.uk:80/\";\\n  wbinfo.timestamp = \"19961104034437\";\\n  wbinfo.request_ts = \"19961104034437\";\\n  wbinfo.prefix = decodeURI(\"https://webarchive.nationalarchives.gov.uk/ukgwa/\");\\n  wbinfo.mod = \"mp_\";\\n  wbinfo.is_framed = true;\\n  wbinfo.is_live = false;\\n  wbinfo.coll = \"ukgwa\";\\n  wbinfo.proxy_magic = \"\";\\n  wbinfo.static_prefix = \"https://webarchive.nationalarchives.gov.uk/static/\";\\n  wbinfo.enable_auto_fetch = false;\\n\\n \\n\\n  wbinfo.wombat_ts = \"19961104034437\";\\n  wbinfo.wombat_sec = \"847079077\";\\n  wbinfo.wombat_scheme = \"http\";\\n  wbinfo.wombat_host = \"www.environment-agency.gov.uk:80\";\\n\\n  wbinfo.wombat_opts = {};\\n\\n  if (window && window._WBWombatInit) {\\n    window._WBWombatInit(wbinfo);\\n  }\\n\\n\\nEnvironment Agency Home Page\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWelcome to the Environment Agency of England and Wales Web Site.\\n\\nA text only version of this site is available.\\nA key feature of this site is our State of the Environment report: this is a snapshot look at the pressures on the environment and how the quality of the environment has changed over the last twenty-five or so years.\\n\\n\\nThis web site will be regularly updated and enhanced to provide comprehensive information and advice on the protection and management of the environment.  Look in the information and resource pages for details on how to contact us.\\n\\n\\nYou can also request copies of our  publications and leaflets on line and review the educational  services we will be offering.  And, of course we encourage you to give us your comments \\non any aspect of the Agency. \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTo find specific information you can directly search the entire content of this site. An index is also available to aid navigation.\\nPlease enter your search request here:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n© Environment Agency 1996. If you have any difficulties with this site please contact the Webmaster.  Don\\'t forget to register to be kept up to date with any changes\\n\\n\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HRiKqjO9eyw"
      },
      "source": [
        "Thankfully BeautifulSoup makes it easy to remove script elements from the HTML. This time we get pure text, however, if we were to compare this with the original web page we see that text from menus is also included. This might be ok for an individual page but when performing text analysis across a site the menu items will be repeated for every page thereby creating unwanted noise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMb0NC-a96xm",
        "outputId": "24415717-d887-4fd9-deea-3f35a27679d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d08019e8f1ee4f179575d9e41a4b002c",
            "d36a392298324549a8daacc853aa1c94",
            "791b1da7ac7c47129eba54b425f1f5fd"
          ]
        }
      },
      "source": [
        "example_dropdown  # Please run me"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d08019e8f1ee4f179575d9e41a4b002c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Dropdown(options=('Environment Agency', 'Salt', 'Butterflies', 'Space Education', 'Professional Standards', 'I…"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75mhxtNQ9EVK",
        "outputId": "31596f9f-4a8b-4063-a747-d2d5c7df875a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "source": [
        "ex_id = example_dropdown.index\n",
        "ex = examples[ex_id]\n",
        "ex_url = UKGWAurl(ex[2] + \"/\" + ex[1])\n",
        "page = requests.get(ex_url.get_url(crawl=True))\n",
        "soup = BeautifulSoup(page.content, 'html.parser')\n",
        "for s in soup.select('script'):\n",
        "    s.extract()\n",
        "soup.get_text().replace(\"\\n\",\" \").replace(\"  \",\" \")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"    Environment Agency Home Page      Welcome to the Environment Agency of England and Wales Web Site. A text only version of this site is available. A key feature of this site is our State of the Environment report: this is a snapshot look at the pressures on the environment and how the quality of the environment has changed over the last twenty-five or so years.  This web site will be regularly updated and enhanced to provide comprehensive information and advice on the protection and management of the environment. Look in the information and resource pages for details on how to contact us.  You can also request copies of our publications and leaflets on line and review the educational services we will be offering. And, of course we encourage you to give us your comments on any aspect of the Agency.      To find specific information you can directly search the entire content of this site. An index is also available to aid navigation. Please enter your search request here:       © Environment Agency 1996. If you have any difficulties with this site please contact the Webmaster. Don't forget to register to be kept up to date with any changes  \""
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4qh1t7M-E8v"
      },
      "source": [
        "A more sophisticated approach to extracting content is to use a boilerplate removal tool, such as boilerpy3. This tool will strip out all of the menus and only return the textual content of the page.\n",
        "\n",
        "The tool needs to be used with care though. While the first example looks great, we see that example 2 returns nothing at all, while example 3 returns a copyright notice. This is because home pages are entry points to a site and are often to help find pages within the site. They are therefore light on content and heavy on boilerplate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LENufOdq-In7",
        "outputId": "adb46693-8cd5-4a83-f9c9-64118cae7165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d08019e8f1ee4f179575d9e41a4b002c",
            "d36a392298324549a8daacc853aa1c94",
            "791b1da7ac7c47129eba54b425f1f5fd"
          ]
        }
      },
      "source": [
        "example_dropdown  # Please run me"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d08019e8f1ee4f179575d9e41a4b002c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Dropdown(options=('Environment Agency', 'Salt', 'Butterflies', 'Space Education', 'Professional Standards', 'I…"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2OzwdYh9_1B",
        "outputId": "75488f44-9c64-468f-a31c-8a048077c1d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        }
      },
      "source": [
        "ex_id = example_dropdown.index\n",
        "ex = examples[ex_id]\n",
        "ex_url = UKGWAurl(ex[2] + \"/\" + ex[1])\n",
        "page = requests.get(ex_url.get_url(crawl=True))\n",
        "soup = BeautifulSoup(page.content, 'html.parser')\n",
        "extractor = extractors.ArticleExtractor()\n",
        "content = extractor.get_content(str(soup))\n",
        "content"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Welcome to the Environment Agency of England and Wales Web Site.\\nA text only version of this site is available.\\nA key feature of this site is our State of the Environment report: this is a snapshot look at the pressures on the environment and how the quality of the environment has changed over the last twenty-five or so years.\\nThis web site will be regularly updated and enhanced to provide comprehensive information and advice on the protection and management of the environment.  Look in the information and resource pages for details on how to contact us.\\nYou can also request copies of our publications and leaflets on line and review the educational services we will be offering.  And, of course we encourage you to give us your comments on any aspect of the Agency.\\nTo find specific information you can directly search the entire content of this site. An index is also available to aid navigation.\\nPlease enter your search request here:\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9Q3bkHa2zDI"
      },
      "source": [
        "## Auto-generating website summaries\n",
        "\n",
        "In the first notebook we looked at the varios descriptions available in Discovery and the A-Z list. The most descriptive of these was the Administrative History from Discovery. Currently this only exists for around one-third of website. The content of the web archive is open and fully indexed so it can be searched but one feature of a good catalogue description is that it provides an overview of a document to let the user know whether that document is worth opening or requesting from the reading room.\n",
        "\n",
        "The great thing about computational access is that in the absence of a catalogue summary we can automate the creation of our own. Using some of the code from earlier to find links, combined with the boilerplate removal tool, we can extract the content from pages linked to on the home page of a site, which are part of that site.\n",
        "\n",
        "Then we can apply a machine learning algorithm called Document Summarisation (from the gensim NLP library) to summarise all of the pages into a short paragraph.\n",
        "We will try it for one of the earlier examples. First, we crawl each linked to page and extract the content into a list:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHwoS1GPDzim"
      },
      "source": [
        "We can compare some of these results with the Administrative History from the first notebook. First we need to set up the data including extracting from the Discovery API, as in notebook 1.\n",
        "\n",
        "<b>Estimated running time 40 seconds</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCDap3F1Dyie"
      },
      "source": [
        "W = UKGWAIndex()\n",
        "W.indexfromweb()\n",
        "W.discoveryfromfile(data_folder + 'ukgwa_catrefs.txt')\n",
        "disco_web_lookup = {}\n",
        "ex_urls = [ex[1] for ex in examples]\n",
        "for w in W:\n",
        "    url = W.get_field(w, 'URL')\n",
        "    if url[-1] == \"/\":\n",
        "        url = url[:-1]\n",
        "    if url in ex_urls:\n",
        "        catref = W.get_field(w, 'CATREF')\n",
        "        disco_web_lookup[catref] = w\n",
        "\n",
        "D = DiscoSearch()\n",
        "D.add_entry('web AND snapshots')\n",
        "example_admin = {}\n",
        "for d in D:\n",
        "    if D.get_field(d, 'reference') in disco_web_lookup:\n",
        "        web_ref = disco_web_lookup[D.get_field(d, 'reference')]\n",
        "        url = W.get_field(web_ref, 'URL')\n",
        "        if url[-1] == \"/\":\n",
        "            url = url[:-1]\n",
        "        example_admin[W.get_field(web_ref, 'URL')] = D.get_field(d, 'adminHistory')\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jLYAUmGOAIA"
      },
      "source": [
        "This code performs the crawling of the pages linked to from the home page (within the same site). It then summarises each page using the summarization function from gensim, and stores a list of the summaries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c-_yitZ-Xeg",
        "outputId": "36fdc212-af73-4648-aabd-78b92f2bedc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d08019e8f1ee4f179575d9e41a4b002c",
            "d36a392298324549a8daacc853aa1c94",
            "791b1da7ac7c47129eba54b425f1f5fd"
          ]
        }
      },
      "source": [
        "example_dropdown"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d08019e8f1ee4f179575d9e41a4b002c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Dropdown(options=('Environment Agency', 'Salt', 'Butterflies', 'Space Education', 'Professional Standards', 'I…"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUQueF9kr1gu",
        "outputId": "3fa97708-0c65-42b7-e6eb-e85e9c9e491e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ex_id = example_dropdown.index\n",
        "ex = examples[ex_id]\n",
        "ex_url = UKGWAurl(ex[2] + \"/\" + ex[1])\n",
        "page = requests.get(ex_url.get_url(crawl=True))\n",
        "soup = BeautifulSoup(page.content, 'html.parser')\n",
        "\n",
        "print(\"Links from\", ex_url.get_url(prefix=False))\n",
        "links = soup.find_all('a')\n",
        "summaries = []\n",
        "\n",
        "\n",
        "for ln in links:\n",
        "    if ln.has_attr('href'):\n",
        "        href = ln['href']\n",
        "        if href[0] == \"#\":\n",
        "            continue\n",
        "        if href[0:2] == \"./\":\n",
        "            href = href[2:]\n",
        "        parent_url = UKGWAurl(ex[2] + \"/\" + ex[1])\n",
        "        link_url = UKGWAurl(href, parent_url)\n",
        "        if link_url.get_domain() != parent_url.get_domain():\n",
        "            continue\n",
        "        print(\"\\t\", href, link_url)\n",
        "        page = requests.get(link_url.get_url(crawl=True))\n",
        "        soup = BeautifulSoup(page.content, 'html.parser')\n",
        "        extractor = extractors.ArticleExtractor()\n",
        "        content = extractor.get_content(str(soup))\n",
        "        summary = summarizer.summarize(content, ratio = 0.2)\n",
        "        summaries.append(summary)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Links from 19961104034437/http://www.environment-agency.gov.uk:80\n",
            "\t /ukgwa/19961104034437mp_/http://www.environment-agency.gov.uk:80/cgi-bin/imagemap/maps/ea-home.map https://webarchive.nationalarchives.gov.uk/ukgwa/19961104034437/http://www.environment-agency.gov.uk:80/ukgwa/19961104034437mp_/http:/www.environment-agency.gov.uk:80/cgi-bin/imagemap/maps/ea-home.map\n",
            "\t who.html https://webarchive.nationalarchives.gov.uk/ukgwa/19961104034437/http://www.environment-agency.gov.uk:80/who.html\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: SAX input contains nested A elements -- You have probably hit a bug in your HTML parser (e.g., NekoHTML bug #2909310). Please clean the HTML externally and feed it to BoilerPy3 again. Trying to recover somehow...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t /ukgwa/19961104034437mp_/http://www.environment-agency.gov.uk:80/text/home.html https://webarchive.nationalarchives.gov.uk/ukgwa/19961104034437/http://www.environment-agency.gov.uk:80/ukgwa/19961104034437mp_/http:/www.environment-agency.gov.uk:80/text/home.html\n",
            "\t s-enviro.html https://webarchive.nationalarchives.gov.uk/ukgwa/19961104034437/http://www.environment-agency.gov.uk:80/s-enviro.html\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: SAX input contains nested A elements -- You have probably hit a bug in your HTML parser (e.g., NekoHTML bug #2909310). Please clean the HTML externally and feed it to BoilerPy3 again. Trying to recover somehow...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t /ukgwa/19961104034437mp_/http://www.environment-agency.gov.uk:80/new.html https://webarchive.nationalarchives.gov.uk/ukgwa/19961104034437/http://www.environment-agency.gov.uk:80/ukgwa/19961104034437mp_/http:/www.environment-agency.gov.uk:80/new.html\n",
            "\t info.html https://webarchive.nationalarchives.gov.uk/ukgwa/19961104034437/http://www.environment-agency.gov.uk:80/info.html\n",
            "\t publications.html https://webarchive.nationalarchives.gov.uk/ukgwa/19961104034437/http://www.environment-agency.gov.uk:80/publications.html\n",
            "\t education.html https://webarchive.nationalarchives.gov.uk/ukgwa/19961104034437/http://www.environment-agency.gov.uk:80/education.html\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: SAX input contains nested A elements -- You have probably hit a bug in your HTML parser (e.g., NekoHTML bug #2909310). Please clean the HTML externally and feed it to BoilerPy3 again. Trying to recover somehow...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t feedback.html https://webarchive.nationalarchives.gov.uk/ukgwa/19961104034437/http://www.environment-agency.gov.uk:80/feedback.html\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: SAX input contains nested A elements -- You have probably hit a bug in your HTML parser (e.g., NekoHTML bug #2909310). Please clean the HTML externally and feed it to BoilerPy3 again. Trying to recover somehow...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t search.html https://webarchive.nationalarchives.gov.uk/ukgwa/19961104034437/http://www.environment-agency.gov.uk:80/search.html\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: SAX input contains nested A elements -- You have probably hit a bug in your HTML parser (e.g., NekoHTML bug #2909310). Please clean the HTML externally and feed it to BoilerPy3 again. Trying to recover somehow...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t /ukgwa/19961104034437mp_/http://www.environment-agency.gov.uk:80/cgi-bin/imagemap/maps/ea-nav.map https://webarchive.nationalarchives.gov.uk/ukgwa/19961104034437/http://www.environment-agency.gov.uk:80/ukgwa/19961104034437mp_/http:/www.environment-agency.gov.uk:80/cgi-bin/imagemap/maps/ea-nav.map\n",
            "\t /ukgwa/19961104034437mp_/http://www.environment-agency.gov.uk:80/new.html https://webarchive.nationalarchives.gov.uk/ukgwa/19961104034437/http://www.environment-agency.gov.uk:80/ukgwa/19961104034437mp_/http:/www.environment-agency.gov.uk:80/new.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hKs8N6f5IKX"
      },
      "source": [
        "Next we concatenate all of those summaries together into one big document and summarise that. You can experiment with the length of the summary using the word count parameter but 100 words produces a nice summary which provides an overview of the web site.\n",
        "\n",
        "It is not a catalogue description, it is built from heuristics not knowledge, but it is a powerful technique and this notebook environment provides an ideal playground to try it out.\n",
        "\n",
        "Run this code to see the result and to compare it against the human curated Administrative History:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OC-ZkNi1gjv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "709c84de-34a4-4d02-9f1b-bca3885b7e79"
      },
      "source": [
        "all_summaries = \"\\n\".join(summaries)\n",
        "print(ex[1])\n",
        "print(\"\")\n",
        "print(\"Auto summary\")\n",
        "print(summarizer.summarize(all_summaries, word_count=100))\n",
        "print(\"\")\n",
        "print(\"Admin History\")\n",
        "if ex[0] in example_admin:\n",
        "    print(example_admin[ex[1]])\n",
        "else:\n",
        "    print(example_admin[ex[1] + \"/\"])\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "http://www.environment-agency.gov.uk:80\n",
            "\n",
            "Auto summary\n",
            "\n",
            "\n",
            "Admin History\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-3b2e1a561eff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_admin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_admin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'http://www.environment-agency.gov.uk:80/'"
          ]
        }
      ]
    }
  ]
}